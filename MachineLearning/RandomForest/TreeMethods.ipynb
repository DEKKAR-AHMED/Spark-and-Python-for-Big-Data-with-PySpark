{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TreeMethods Review "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Tree, ....\n",
    "\n",
    "- How to choose to split in some features first and not in others, for this we will use Entropy H(x) and information gain  IG(S,A)(mathematical methods) to choose the best split\n",
    "\n",
    "## Random Forest\n",
    "- we can use many tress with a random rample features chosen  ...... plus details in the future.\n",
    "\n",
    "- take the average vote of all decision Tree that we made then take a decision at the most frequent \n",
    "\n",
    "- The point of Random Forest is pass the problem of one very Strong Feature. because in this case all the decision Tree will use this feature as the top split == > resulting in an Ensemble of similar trees that are highly correlated what does not not significantly reduce variance. For this reason we use random select feature in each tree, as keeping randomly features form each split Random Forest Decorrelates the Trees, such that the averaging process can reduce the variance of the resulting model\n",
    "\n",
    "\n",
    "## Gradient Boosted Trees \n",
    "\n",
    "- involves Tree fondamental elemetns \n",
    "    - loss function to be optimized  : a function to determine how far off our prediction are for expamle (Squared Error) for regression and \n",
    "    Logarithmic Loss for classification\n",
    "    - weak learner to make predictions : in Decision trees are used as the weak learner in gradient boosting \n",
    "    - an additive model to ass a weak learners to minimze the loss function\n",
    "        - train a wwak model m using data samples drawn according to some weight distribution\n",
    "        - increase the weight of samples that are misclassified by the model m, and decrease the weight of the samples are classified correctly in the model m \n",
    "        - Train new weak model using the samples drawn according to the updates wight distribution.\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Start un Example "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.appName(\"mytree\").getOrCreate()\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.classification import RandomForestClassifier, GBTClassifier, DecisionTreeClassifier\n",
    "# we can use the for regression as well "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = spark.read.format(\"libsvm\").load(\"../../Data/sample_libsvm_data.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- label: double (nullable = true)\n",
      " |-- features: vector (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+--------------------+\n",
      "|label|            features|\n",
      "+-----+--------------------+\n",
      "|  0.0|(692,[127,128,129...|\n",
      "|  1.0|(692,[158,159,160...|\n",
      "|  1.0|(692,[124,125,126...|\n",
      "|  1.0|(692,[152,153,154...|\n",
      "|  1.0|(692,[151,152,153...|\n",
      "|  0.0|(692,[129,130,131...|\n",
      "|  1.0|(692,[158,159,160...|\n",
      "|  1.0|(692,[99,100,101,...|\n",
      "|  0.0|(692,[154,155,156...|\n",
      "|  0.0|(692,[127,128,129...|\n",
      "|  1.0|(692,[154,155,156...|\n",
      "|  0.0|(692,[153,154,155...|\n",
      "|  0.0|(692,[151,152,153...|\n",
      "|  1.0|(692,[129,130,131...|\n",
      "|  0.0|(692,[154,155,156...|\n",
      "|  1.0|(692,[150,151,152...|\n",
      "|  0.0|(692,[124,125,126...|\n",
      "|  0.0|(692,[152,153,154...|\n",
      "|  1.0|(692,[97,98,99,12...|\n",
      "|  1.0|(692,[124,125,126...|\n",
      "+-----+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data ,test_data = data.randomSplit([.7,.3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtc = DecisionTreeClassifier(labelCol=\"label\",featuresCol=\"features\")\n",
    "# there are other parametre we can play with knowing the mathmatical backround "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfc = RandomForestClassifier(numTrees = 100 ) \n",
    "gbt = GBTClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtc_model = dtc.fit(train_data)\n",
    "rfc_model = rfc.fit(train_data)\n",
    "gbt_model = gbt.fit(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtc_preds = dtc_model.transform(test_data)\n",
    "rfc_preds = rfc_model.transform(test_data)\n",
    "gbt_preds = gbt_model.transform(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+--------------------+-------------+-----------+----------+\n",
      "|label|            features|rawPrediction|probability|prediction|\n",
      "+-----+--------------------+-------------+-----------+----------+\n",
      "|  0.0|(692,[95,96,97,12...|   [30.0,0.0]|  [1.0,0.0]|       0.0|\n",
      "|  0.0|(692,[121,122,123...|   [30.0,0.0]|  [1.0,0.0]|       0.0|\n",
      "|  0.0|(692,[122,123,148...|   [30.0,0.0]|  [1.0,0.0]|       0.0|\n",
      "|  0.0|(692,[124,125,126...|   [30.0,0.0]|  [1.0,0.0]|       0.0|\n",
      "|  0.0|(692,[126,127,128...|   [30.0,0.0]|  [1.0,0.0]|       0.0|\n",
      "|  0.0|(692,[126,127,128...|   [30.0,0.0]|  [1.0,0.0]|       0.0|\n",
      "|  0.0|(692,[126,127,128...|   [30.0,0.0]|  [1.0,0.0]|       0.0|\n",
      "|  0.0|(692,[127,128,129...|   [30.0,0.0]|  [1.0,0.0]|       0.0|\n",
      "|  0.0|(692,[127,128,129...|   [30.0,0.0]|  [1.0,0.0]|       0.0|\n",
      "|  0.0|(692,[128,129,130...|   [30.0,0.0]|  [1.0,0.0]|       0.0|\n",
      "|  0.0|(692,[153,154,155...|   [30.0,0.0]|  [1.0,0.0]|       0.0|\n",
      "|  0.0|(692,[154,155,156...|   [0.0,39.0]|  [0.0,1.0]|       1.0|\n",
      "|  0.0|(692,[155,156,180...|   [30.0,0.0]|  [1.0,0.0]|       0.0|\n",
      "|  1.0|(692,[99,100,101,...|   [30.0,0.0]|  [1.0,0.0]|       0.0|\n",
      "|  1.0|(692,[100,101,102...|   [0.0,39.0]|  [0.0,1.0]|       1.0|\n",
      "|  1.0|(692,[124,125,126...|   [0.0,39.0]|  [0.0,1.0]|       1.0|\n",
      "|  1.0|(692,[124,125,126...|   [0.0,39.0]|  [0.0,1.0]|       1.0|\n",
      "|  1.0|(692,[124,125,126...|   [0.0,39.0]|  [0.0,1.0]|       1.0|\n",
      "|  1.0|(692,[125,126,127...|   [0.0,39.0]|  [0.0,1.0]|       1.0|\n",
      "|  1.0|(692,[125,126,153...|   [0.0,39.0]|  [0.0,1.0]|       1.0|\n",
      "+-----+--------------------+-------------+-----------+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dtc_preds.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+--------------------+--------------------+--------------------+----------+\n",
      "|label|            features|       rawPrediction|         probability|prediction|\n",
      "+-----+--------------------+--------------------+--------------------+----------+\n",
      "|  0.0|(692,[95,96,97,12...|[1.54350200272498...|[0.95635347857270...|       0.0|\n",
      "|  0.0|(692,[121,122,123...|[1.54350200272498...|[0.95635347857270...|       0.0|\n",
      "|  0.0|(692,[122,123,148...|[1.54350200272498...|[0.95635347857270...|       0.0|\n",
      "|  0.0|(692,[124,125,126...|[1.54350200272498...|[0.95635347857270...|       0.0|\n",
      "|  0.0|(692,[126,127,128...|[1.54350200272498...|[0.95635347857270...|       0.0|\n",
      "|  0.0|(692,[126,127,128...|[1.54350200272498...|[0.95635347857270...|       0.0|\n",
      "|  0.0|(692,[126,127,128...|[1.54350200272498...|[0.95635347857270...|       0.0|\n",
      "|  0.0|(692,[127,128,129...|[1.54350200272498...|[0.95635347857270...|       0.0|\n",
      "|  0.0|(692,[127,128,129...|[1.54350200272498...|[0.95635347857270...|       0.0|\n",
      "|  0.0|(692,[128,129,130...|[1.54350200272498...|[0.95635347857270...|       0.0|\n",
      "|  0.0|(692,[153,154,155...|[1.54350200272498...|[0.95635347857270...|       0.0|\n",
      "|  0.0|(692,[154,155,156...|[-0.8869698362398...|[0.14505307606376...|       1.0|\n",
      "|  0.0|(692,[155,156,180...|[1.54350200272498...|[0.95635347857270...|       0.0|\n",
      "|  1.0|(692,[99,100,101,...|[1.54350200272498...|[0.95635347857270...|       0.0|\n",
      "|  1.0|(692,[100,101,102...|[-1.5435020027249...|[0.04364652142729...|       1.0|\n",
      "|  1.0|(692,[124,125,126...|[-1.5435020027249...|[0.04364652142729...|       1.0|\n",
      "|  1.0|(692,[124,125,126...|[-1.5435020027249...|[0.04364652142729...|       1.0|\n",
      "|  1.0|(692,[124,125,126...|[-1.5435020027249...|[0.04364652142729...|       1.0|\n",
      "|  1.0|(692,[125,126,127...|[-1.5435020027249...|[0.04364652142729...|       1.0|\n",
      "|  1.0|(692,[125,126,153...|[-1.5435020027249...|[0.04364652142729...|       1.0|\n",
      "+-----+--------------------+--------------------+--------------------+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "gbt_preds.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc = MulticlassClassificationEvaluator(metricName=\"accuracy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9354838709677419"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acc.evaluate(dtc_preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Important for random forest for example "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#rfc_model.featureImportances \n",
    "\n",
    "# the hight number the most important the features is for the models "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Real Example for  Decision Tree, Random Forest , Gradien Boosting "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.appName(\"example\").getOrCreate()\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.classification import RandomForestClassifier, GBTClassifier, DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['School',\n",
       " 'Private',\n",
       " 'Apps',\n",
       " 'Accept',\n",
       " 'Enroll',\n",
       " 'Top10perc',\n",
       " 'Top25perc',\n",
       " 'F_Undergrad',\n",
       " 'P_Undergrad',\n",
       " 'Outstate',\n",
       " 'Room_Board',\n",
       " 'Books',\n",
       " 'Personal',\n",
       " 'PhD',\n",
       " 'Terminal',\n",
       " 'S_F_Ratio',\n",
       " 'perc_alumni',\n",
       " 'Expend',\n",
       " 'Grad_Rate']"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = spark.read.csv(\"../../Data/College.csv\",header=True,inferSchema=True)\n",
    "data.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# we will try to predicted the private feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import VectorAssembler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "assembler = VectorAssembler(inputCols=['Apps',\n",
    " 'Accept',\n",
    " 'Enroll',\n",
    " 'Top10perc',\n",
    " 'Top25perc',\n",
    " 'F_Undergrad',\n",
    " 'P_Undergrad',\n",
    " 'Outstate',\n",
    " 'Room_Board',\n",
    " 'Books',\n",
    " 'Personal',\n",
    " 'PhD',\n",
    " 'Terminal',\n",
    " 'S_F_Ratio',\n",
    " 'perc_alumni',\n",
    " 'Expend',\n",
    " 'Grad_Rate'],outputCol=\"features\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = assembler.transform(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import StringIndexer\n",
    "indexer = StringIndexer(inputCol=\"Private\",outputCol=\"PrivateIndex\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_fixed = indexer.fit(output).transform(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- School: string (nullable = true)\n",
      " |-- Private: string (nullable = true)\n",
      " |-- Apps: integer (nullable = true)\n",
      " |-- Accept: integer (nullable = true)\n",
      " |-- Enroll: integer (nullable = true)\n",
      " |-- Top10perc: integer (nullable = true)\n",
      " |-- Top25perc: integer (nullable = true)\n",
      " |-- F_Undergrad: integer (nullable = true)\n",
      " |-- P_Undergrad: integer (nullable = true)\n",
      " |-- Outstate: integer (nullable = true)\n",
      " |-- Room_Board: integer (nullable = true)\n",
      " |-- Books: integer (nullable = true)\n",
      " |-- Personal: integer (nullable = true)\n",
      " |-- PhD: integer (nullable = true)\n",
      " |-- Terminal: integer (nullable = true)\n",
      " |-- S_F_Ratio: double (nullable = true)\n",
      " |-- perc_alumni: integer (nullable = true)\n",
      " |-- Expend: integer (nullable = true)\n",
      " |-- Grad_Rate: integer (nullable = true)\n",
      " |-- features: vector (nullable = true)\n",
      " |-- PrivateIndex: double (nullable = false)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "output_fixed.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_final = output_fixed.select([\"features\",\"PrivateIndex\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, test_data = data_final.randomSplit([.7,.3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating  the model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.classification import RandomForestClassifier, GBTClassifier, DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "randomForest = RandomForestClassifier (labelCol=\"PrivateIndex\")\n",
    "GradBoos = GBTClassifier(labelCol=\"PrivateIndex\")\n",
    "DeciTree = DecisionTreeClassifier(labelCol=\"PrivateIndex\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "randomForest_model = randomForest.fit(train_data)\n",
    "GradBoos_model = GradBoos.fit(train_data)\n",
    "DeciTree_model = DeciTree.fit(train_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "randomForestPred = randomForest_model.transform(test_data)\n",
    "GradBoos_modelPred = GradBoos_model.transform(test_data)\n",
    "DeciTree_model_modelPred = DeciTree_model.transform(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- features: vector (nullable = true)\n",
      " |-- PrivateIndex: double (nullable = false)\n",
      " |-- rawPrediction: vector (nullable = true)\n",
      " |-- probability: vector (nullable = true)\n",
      " |-- prediction: double (nullable = false)\n",
      "\n",
      "root\n",
      " |-- features: vector (nullable = true)\n",
      " |-- PrivateIndex: double (nullable = false)\n",
      " |-- rawPrediction: vector (nullable = true)\n",
      " |-- probability: vector (nullable = true)\n",
      " |-- prediction: double (nullable = false)\n",
      "\n",
      "root\n",
      " |-- features: vector (nullable = true)\n",
      " |-- PrivateIndex: double (nullable = false)\n",
      " |-- rawPrediction: vector (nullable = true)\n",
      " |-- probability: vector (nullable = true)\n",
      " |-- prediction: double (nullable = false)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "randomForestPred.printSchema()\n",
    "GradBoos_modelPred.printSchema()\n",
    "DeciTree_model_modelPred.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation Matrix "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_binary_eval = BinaryClassificationEvaluator(labelCol=\"PrivateIndex\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "resutl = my_binary_eval.evaluate(randomForestPred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC for Random Forest\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9711493933500035"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"AUC for Random Forest\")\n",
    "resutl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC for Decision Tree\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.899370195424655"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resutl = my_binary_eval.evaluate(DeciTree_model_modelPred)\n",
    "print(\"AUC for Decision Tree\")\n",
    "resutl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC for Gradien Boosting \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9574881911642124"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resutl = my_binary_eval.evaluate(GradBoos_modelPred)\n",
    "print(\"AUC for Gradien Boosting \")\n",
    "resutl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Accuracy,...."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for Decision Tree\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9243697478991597"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_multi_eval = MulticlassClassificationEvaluator(labelCol=\"PrivateIndex\", metricName=\"accuracy\")\n",
    "resutl = my_multi_eval.evaluate(DeciTree_model_modelPred)\n",
    "print(\"Accuracy for Decision Tree\")\n",
    "resutl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
